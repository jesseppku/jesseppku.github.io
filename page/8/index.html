<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"sir0.net","root":"/","scheme":"Muse","version":"7.7.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="吴梦梦、刘玥和SL炮叔">
<meta property="og:url" content="http://sir0.net/page/8/index.html">
<meta property="og:site_name" content="吴梦梦、刘玥和SL炮叔">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="sir0.net">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://sir0.net/page/8/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false
  };
</script>

  <title>吴梦梦、刘玥和SL炮叔</title>
  


  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?b111bff4f8ef5699b270a9ec8dae6cef";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">吴梦梦、刘玥和SL炮叔</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
  </ul>

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://sir0.net/%E7%88%AC%E8%99%AB%E7%88%AC%E5%8F%96m3u8%E8%A7%86%E9%A2%91%E6%96%87%E4%BB%B6/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="sir0.net">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="吴梦梦、刘玥和SL炮叔">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/%E7%88%AC%E8%99%AB%E7%88%AC%E5%8F%96m3u8%E8%A7%86%E9%A2%91%E6%96%87%E4%BB%B6/" class="post-title-link" itemprop="url">爬虫爬取m3u8视频文件</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-03-07 23:00:57" itemprop="dateCreated datePublished" datetime="2020-03-07T23:00:57+08:00">2020-03-07</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-03-06 11:39:52" itemprop="dateModified" datetime="2020-03-06T11:39:52+08:00">2020-03-06</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="一-m3u8视频格式"><a href="#一-m3u8视频格式" class="headerlink" title="一.m3u8视频格式"></a>一.m3u8视频格式</h2><p>一般<code>m3u8</code>文件和 视频流<code>ts</code>文件放在同一目录<br>而<code>m3u8</code>文件格式存放的一般都是<code>ts</code> 文件的一个列表</p>
<h2 id="二-根据m3u8视频存放以及写法的规律"><a href="#二-根据m3u8视频存放以及写法的规律" class="headerlink" title="二.根据m3u8视频存放以及写法的规律"></a>二.根据m3u8视频存放以及写法的规律</h2><p><code>思路</code></p>
<ul>
<li>我们一般网站上能找到的<code>m3u8</code>的url</li>
<li>将m3u8格式的文件下载下来</li>
<li>然后打开m3u8找到里面所有的ts的路径<code>可以用正则匹配</code></li>
<li>然后<code>m3u8</code>的url进行替换比如<code>https:www.xxx/xxx/xxx.m3u8</code>改成<code>https:www.xxx/xxx/xxx.ts</code></li>
<li>为什么这样改因为一般不出意外的话<code>m3u8</code>和<code>ts</code> 是放在同一目录</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://sir0.net/%E7%88%AC%E8%99%AB%E5%93%8D%E5%BA%94%E4%BF%A1%E6%81%AF%E4%B9%B1%E7%A0%81%E8%A7%A3%E5%86%B3%E6%96%B9%E5%BC%8F/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="sir0.net">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="吴梦梦、刘玥和SL炮叔">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/%E7%88%AC%E8%99%AB%E5%93%8D%E5%BA%94%E4%BF%A1%E6%81%AF%E4%B9%B1%E7%A0%81%E8%A7%A3%E5%86%B3%E6%96%B9%E5%BC%8F/" class="post-title-link" itemprop="url">爬虫响应信息乱码解决方式</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-03-07 23:00:57" itemprop="dateCreated datePublished" datetime="2020-03-07T23:00:57+08:00">2020-03-07</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-03-06 11:40:08" itemprop="dateModified" datetime="2020-03-06T11:40:08+08:00">2020-03-06</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="一-用requests库自带的自动检测"><a href="#一-用requests库自带的自动检测" class="headerlink" title="一.用requests库自带的自动检测"></a>一.用requests库自带的自动检测</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">response = requests.get(<span class="string">'https://wwww.baidu.com'</span>)</span><br><span class="line">response.encoding =response.apparent_encoding <span class="comment"># 这个容易炸</span></span><br></pre></td></tr></table></figure>
<h2 id="二-用pycharm编辑器"><a href="#二-用pycharm编辑器" class="headerlink" title="二.用pycharm编辑器"></a>二.用pycharm编辑器</h2><ul>
<li>第一步:将爬取数据保存txt中</li>
<li>第二步:用pycharm打开txt</li>
<li>然后pycharm会提示你什么编码</li>
</ul>
<h2 id="三-用网页终端console-个人比较推荐"><a href="#三-用网页终端console-个人比较推荐" class="headerlink" title="三.用网页终端console(个人比较推荐)"></a>三.用网页终端console(个人比较推荐)</h2><p><code>在你爬取的网站</code></p>
<ul>
<li>浏览器F12</li>
<li>点击console</li>
<li>执行js命令<code>document.charset</code></li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://sir0.net/%E7%88%AC%E8%99%AB%E4%B9%8BScarpy.Request/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="sir0.net">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="吴梦梦、刘玥和SL炮叔">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/%E7%88%AC%E8%99%AB%E4%B9%8BScarpy.Request/" class="post-title-link" itemprop="url">爬虫之Scarpy.Request</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-03-07 23:00:57" itemprop="dateCreated datePublished" datetime="2020-03-07T23:00:57+08:00">2020-03-07</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-03-06 11:39:29" itemprop="dateModified" datetime="2020-03-06T11:39:29+08:00">2020-03-06</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>一 .Request<br>1.request<br>Scarpy中的HTTP请求对象<br>1.1.Requse的构造</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#我们ctrl+左键可以看到Scarpy.Request的代码</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Request</span><span class="params">(object_ref)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, url, callback=None, method=<span class="string">'GET'</span>, headers=None, body=None,</span></span></span><br><span class="line"><span class="function"><span class="params">                 cookies=None, meta=None, encoding=<span class="string">'utf-8'</span>, priority=<span class="number">0</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                 dont_filter=False, errback=None, flags=None)</span>:</span></span><br><span class="line"></span><br><span class="line"> 其中我们可以看出描述他的有这几个因素</span><br><span class="line"><span class="number">1.</span>url:请求页面的地址(必须有这个参数)</span><br><span class="line"><span class="number">2.</span>callback:页面解析参数,(默认调用Spider的parse的方法)</span><br><span class="line"><span class="number">3.</span>method:http的请求方法,默认为<span class="string">'GET'</span></span><br><span class="line"><span class="number">4.</span>header:请求头部字典,NONE是不发生送给COOKIES</span><br><span class="line"><span class="number">5.</span>body:请求正文,bytes或者str数据类型</span><br><span class="line"><span class="number">6.</span>cookies:COOKIES信息字典</span><br><span class="line"><span class="number">7</span>meta:(我没法理解)</span><br><span class="line"><span class="number">8.</span>encoding:编码方式</span><br><span class="line"><span class="number">9.</span>priority:请求优先级,默认值为<span class="number">0</span></span><br><span class="line"><span class="number">10.</span>dont_filter:默认情况下是<span class="literal">False</span>对同一url发送多次请求不过会被过滤,对于变换的网页我们最好改成Ture防止被过滤</span><br><span class="line"><span class="number">11.</span>errback:请求时发送错误进行回调</span><br><span class="line"><span class="number">12.</span>flags:(不清楚)</span><br></pre></td></tr></table></figure>
<p>1.2常用的几个参数</p>
<ul>
<li>url</li>
<li>method</li>
<li>headers</li>
<li>body</li>
<li>meta</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://sir0.net/%E7%88%AC%E8%99%AB%E6%95%B4%E7%90%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="sir0.net">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="吴梦梦、刘玥和SL炮叔">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/%E7%88%AC%E8%99%AB%E6%95%B4%E7%90%86/" class="post-title-link" itemprop="url">爬虫整理</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-03-07 23:00:57" itemprop="dateCreated datePublished" datetime="2020-03-07T23:00:57+08:00">2020-03-07</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-03-06 11:39:53" itemprop="dateModified" datetime="2020-03-06T11:39:53+08:00">2020-03-06</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="一-爬虫原则"><a href="#一-爬虫原则" class="headerlink" title="一.爬虫原则"></a>一.爬虫原则</h2><h3 id="爬虫的盗亦有道Robots协议"><a href="#爬虫的盗亦有道Robots协议" class="headerlink" title="爬虫的盗亦有道Robots协议"></a><a href="https://www.cnblogs.com/pythonywy/p/11114417.html" target="_blank" rel="noopener">爬虫的盗亦有道Robots协议</a></h3><h2 id="二-爬虫页面获取基础"><a href="#二-爬虫页面获取基础" class="headerlink" title="二.爬虫页面获取基础"></a>二.爬虫页面获取基础</h2><h3 id="Requests库概念"><a href="#Requests库概念" class="headerlink" title="Requests库概念"></a><a href="https://www.cnblogs.com/pythonywy/p/11114177.html" target="_blank" rel="noopener">Requests库概念</a></h3><h3 id="深入requests库params-data-json参数"><a href="#深入requests库params-data-json参数" class="headerlink" title="深入requests库params|data|json参数"></a><a href="https://www.cnblogs.com/pythonywy/p/11311749.html" target="_blank" rel="noopener">深入requests库params|data|json参数</a></h3><h3 id="requeests模块请求常用参数的写法整理"><a href="#requeests模块请求常用参数的写法整理" class="headerlink" title="requeests模块请求常用参数的写法整理"></a><a href="https://www.cnblogs.com/pythonywy/p/11686005.html" target="_blank" rel="noopener">requeests模块请求常用参数的写法整理</a></h3><h3 id="requeests模块响应体属性和方法重新整理"><a href="#requeests模块响应体属性和方法重新整理" class="headerlink" title="requeests模块响应体属性和方法重新整理"></a><a href="https://www.cnblogs.com/pythonywy/p/11686366.html" target="_blank" rel="noopener">requeests模块响应体属性和方法重新整理</a></h3><h3 id="Python3安装与使用urllib2包之小坑"><a href="#Python3安装与使用urllib2包之小坑" class="headerlink" title="Python3安装与使用urllib2包之小坑"></a><a href="https://www.cnblogs.com/pythonywy/p/11215059.html" target="_blank" rel="noopener">Python3安装与使用urllib2包之小坑</a></h3><h3 id="python爬虫执行js代码-execjs"><a href="#python爬虫执行js代码-execjs" class="headerlink" title="python爬虫执行js代码-execjs"></a><a href="https://www.cnblogs.com/pythonywy/p/11715974.html" target="_blank" rel="noopener">python爬虫执行js代码-execjs</a></h3><h2 id="三-爬虫页面解析基础"><a href="#三-爬虫页面解析基础" class="headerlink" title="三.爬虫页面解析基础"></a>三.爬虫页面解析基础</h2><h3 id="url编码本质"><a href="#url编码本质" class="headerlink" title="url编码本质"></a><a href="https://www.cnblogs.com/pythonywy/p/11696583.html" target="_blank" rel="noopener">url编码本质</a></h3><h3 id="BeautifulSoup库概念"><a href="#BeautifulSoup库概念" class="headerlink" title="BeautifulSoup库概念"></a><a href="https://www.cnblogs.com/pythonywy/p/11134481.html" target="_blank" rel="noopener">BeautifulSoup库概念</a></h3><h3 id="python爬虫网页解析之lxml模块"><a href="#python爬虫网页解析之lxml模块" class="headerlink" title="python爬虫网页解析之lxml模块"></a><a href="https://www.cnblogs.com/pythonywy/p/11311094.html" target="_blank" rel="noopener">python爬虫网页解析之lxml模块</a></h3><h3 id="python爬虫网页解析之parsel模块"><a href="#python爬虫网页解析之parsel模块" class="headerlink" title="python爬虫网页解析之parsel模块"></a><a href="https://www.cnblogs.com/pythonywy/p/11311237.html" target="_blank" rel="noopener">python爬虫网页解析之parsel模块</a></h3><h2 id="四-解析后内容获取"><a href="#四-解析后内容获取" class="headerlink" title="四.解析后内容获取"></a>四.解析后内容获取</h2><h3 id="xpath路径的写法"><a href="#xpath路径的写法" class="headerlink" title="xpath路径的写法"></a><a href="https://www.cnblogs.com/pythonywy/p/11082153.html" target="_blank" rel="noopener">xpath路径的写法</a></h3><h3 id="re模块"><a href="#re模块" class="headerlink" title="re模块"></a><a href="https://www.cnblogs.com/pythonywy/p/11018912.html" target="_blank" rel="noopener">re模块</a></h3><h3 id="常用的re模块的正则匹配的表达式"><a href="#常用的re模块的正则匹配的表达式" class="headerlink" title="常用的re模块的正则匹配的表达式"></a><a href="https://www.cnblogs.com/pythonywy/p/11113349.html" target="_blank" rel="noopener">常用的re模块的正则匹配的表达式</a></h3><h3 id="BeautifulSoup的重要操作"><a href="#BeautifulSoup的重要操作" class="headerlink" title="BeautifulSoup的重要操作"></a><a href="https://www.cnblogs.com/pythonywy/p/11308818.html" target="_blank" rel="noopener">BeautifulSoup的重要操作</a></h3><h2 id="五-模仿浏览器爬取"><a href="#五-模仿浏览器爬取" class="headerlink" title="五.模仿浏览器爬取"></a>五.模仿浏览器爬取</h2><h3 id="Selenium模块的安装"><a href="#Selenium模块的安装" class="headerlink" title="Selenium模块的安装"></a><a href="https://www.cnblogs.com/pythonywy/p/11234164.html" target="_blank" rel="noopener">Selenium模块的安装</a></h3><h3 id="深入selenium模块基础操作"><a href="#深入selenium模块基础操作" class="headerlink" title="深入selenium模块基础操作"></a><a href="https://www.cnblogs.com/pythonywy/p/11240805.html" target="_blank" rel="noopener">深入selenium模块基础操作</a></h3><h3 id="深入selenium三种等待方式使用"><a href="#深入selenium三种等待方式使用" class="headerlink" title="深入selenium三种等待方式使用"></a><a href="https://www.cnblogs.com/pythonywy/p/11284800.html" target="_blank" rel="noopener">深入selenium三种等待方式使用</a></h3><h3 id="爬虫selenium中截图"><a href="#爬虫selenium中截图" class="headerlink" title="爬虫selenium中截图"></a><a href="https://www.cnblogs.com/pythonywy/p/11777511.html" target="_blank" rel="noopener">爬虫selenium中截图</a></h3><h3 id="爬虫selenium中动作链接ActionChains"><a href="#爬虫selenium中动作链接ActionChains" class="headerlink" title="爬虫selenium中动作链接ActionChains"></a><a href="https://www.cnblogs.com/pythonywy/p/11777644.html" target="_blank" rel="noopener">爬虫selenium中动作链接ActionChains</a></h3><h3 id="python-pyppeteer模块使用汇总"><a href="#python-pyppeteer模块使用汇总" class="headerlink" title="python-pyppeteer模块使用汇总"></a><a href="https://www.cnblogs.com/pythonywy/p/11972476.html" target="_blank" rel="noopener">python-pyppeteer模块使用汇总</a></h3><h2 id="六-Scrapy框架"><a href="#六-Scrapy框架" class="headerlink" title="六.Scrapy框架"></a>六.Scrapy框架</h2><h3 id="爬虫之Scarpy-Request"><a href="#爬虫之Scarpy-Request" class="headerlink" title="爬虫之Scarpy.Request"></a><a href="https://www.cnblogs.com/pythonywy/p/10922008.html" target="_blank" rel="noopener">爬虫之Scarpy.Request</a></h3><h3 id="Scrapy爬虫框架与常用命令"><a href="#Scrapy爬虫框架与常用命令" class="headerlink" title="Scrapy爬虫框架与常用命令"></a><a href="https://www.cnblogs.com/pythonywy/p/11153670.html" target="_blank" rel="noopener">Scrapy爬虫框架与常用命令</a></h3><h3 id="Scrapy框架的简单使用"><a href="#Scrapy框架的简单使用" class="headerlink" title="Scrapy框架的简单使用"></a><a href="https://www.cnblogs.com/pythonywy/p/11719790.html" target="_blank" rel="noopener">Scrapy框架的简单使用</a></h3><h3 id="scrapy在pycharm配置启动-无需命令行启动-无需命令行启动"><a href="#scrapy在pycharm配置启动-无需命令行启动-无需命令行启动" class="headerlink" title="scrapy在pycharm配置启动(无需命令行启动)无需命令行启动)"></a><a href="https://www.cnblogs.com/pythonywy/p/11728161.html" target="_blank" rel="noopener">scrapy在pycharm配置启动(无需命令行启动)无需命令行启动)</a></h3><h3 id="Scrapy框架-爬虫程序相关属性和方法汇总"><a href="#Scrapy框架-爬虫程序相关属性和方法汇总" class="headerlink" title="Scrapy框架-爬虫程序相关属性和方法汇总"></a><a href="https://www.cnblogs.com/pythonywy/p/11727332.html" target="_blank" rel="noopener">Scrapy框架-爬虫程序相关属性和方法汇总</a></h3><h3 id="scrapy常用配置"><a href="#scrapy常用配置" class="headerlink" title="scrapy常用配置"></a><a href="https://www.cnblogs.com/pythonywy/p/11728817.html" target="_blank" rel="noopener">scrapy常用配置</a></h3><h3 id="关于scrapy中scrapy-Request中的属性"><a href="#关于scrapy中scrapy-Request中的属性" class="headerlink" title="关于scrapy中scrapy.Request中的属性"></a><a href="https://www.cnblogs.com/pythonywy/p/11728307.html" target="_blank" rel="noopener">关于scrapy中scrapy.Request中的属性</a></h3><h3 id="Scrapy中response属性以及内容提取"><a href="#Scrapy中response属性以及内容提取" class="headerlink" title="Scrapy中response属性以及内容提取"></a><a href="https://www.cnblogs.com/pythonywy/p/11964082.html" target="_blank" rel="noopener">Scrapy中response属性以及内容提取</a></h3><h3 id="Scrapy框架-中间件"><a href="#Scrapy框架-中间件" class="headerlink" title="Scrapy框架-中间件"></a><a href="https://www.cnblogs.com/pythonywy/p/11722713.html" target="_blank" rel="noopener">Scrapy框架-中间件</a></h3><h3 id="关于scrapy中如何区分是接着发起请求还是开始保存文件"><a href="#关于scrapy中如何区分是接着发起请求还是开始保存文件" class="headerlink" title="关于scrapy中如何区分是接着发起请求还是开始保存文件"></a><a href="https://www.cnblogs.com/pythonywy/p/11728456.html" target="_blank" rel="noopener">关于scrapy中如何区分是接着发起请求还是开始保存文件</a></h3><h2 id="七-抓包工具"><a href="#七-抓包工具" class="headerlink" title="七.抓包工具"></a>七.抓包工具</h2><h3 id="mitmproxy的使用"><a href="#mitmproxy的使用" class="headerlink" title="mitmproxy的使用"></a><a href="https://www.cnblogs.com/pythonywy/p/11704788.html" target="_blank" rel="noopener">mitmproxy的使用</a></h3><h3 id="Fiddler手机抓包设置"><a href="#Fiddler手机抓包设置" class="headerlink" title="Fiddler手机抓包设置"></a><a href="https://www.cnblogs.com/pythonywy/p/11704749.html" target="_blank" rel="noopener">Fiddler手机抓包设置</a></h3><h3 id="Fiddler抓取内容自动保存本地"><a href="#Fiddler抓取内容自动保存本地" class="headerlink" title="Fiddler抓取内容自动保存本地"></a><a href="https://www.cnblogs.com/pythonywy/p/12033488.html" target="_blank" rel="noopener">Fiddler抓取内容自动保存本地</a></h3><h3 id="fiddler抓包syntaxview窗口乱码"><a href="#fiddler抓包syntaxview窗口乱码" class="headerlink" title="fiddler抓包syntaxview窗口乱码"></a><a href="https://www.cnblogs.com/pythonywy/p/11704821.html" target="_blank" rel="noopener">fiddler抓包syntaxview窗口乱码</a></h3><h2 id="八-实战爬虫"><a href="#八-实战爬虫" class="headerlink" title="八.实战爬虫"></a>八.实战爬虫</h2><h3 id="爬段子"><a href="#爬段子" class="headerlink" title="爬段子"></a><a href="https://www.cnblogs.com/pythonywy/p/10856819.html" target="_blank" rel="noopener">爬段子</a></h3><h3 id="爬图片"><a href="#爬图片" class="headerlink" title="爬图片"></a><a href="https://www.cnblogs.com/pythonywy/p/10856508.html" target="_blank" rel="noopener">爬图片</a></h3><h3 id="爬视频"><a href="#爬视频" class="headerlink" title="爬视频"></a><a href="https://www.cnblogs.com/pythonywy/p/10857032.html" target="_blank" rel="noopener">爬视频</a></h3><h3 id="练手爬虫用urllib模块获取"><a href="#练手爬虫用urllib模块获取" class="headerlink" title="练手爬虫用urllib模块获取"></a><a href="https://www.cnblogs.com/pythonywy/p/11326228.html" target="_blank" rel="noopener">练手爬虫用urllib模块获取</a></h3><h3 id="爬取博客园的所有随笔的url以及计数-还有对应标题"><a href="#爬取博客园的所有随笔的url以及计数-还有对应标题" class="headerlink" title="爬取博客园的所有随笔的url以及计数,还有对应标题"></a><a href="https://www.cnblogs.com/pythonywy/p/11046302.html" target="_blank" rel="noopener">爬取博客园的所有随笔的url以及计数,还有对应标题</a></h3><h3 id="爬取新浪双色彩-信息并进行分析"><a href="#爬取新浪双色彩-信息并进行分析" class="headerlink" title="爬取新浪双色彩,信息并进行分析"></a><a href="https://www.cnblogs.com/pythonywy/p/11152970.html" target="_blank" rel="noopener">爬取新浪双色彩,信息并进行分析</a></h3><h3 id="对于下发的文件进行爬取"><a href="#对于下发的文件进行爬取" class="headerlink" title="对于下发的文件进行爬取"></a><a href="https://www.cnblogs.com/pythonywy/p/11279269.html" target="_blank" rel="noopener">对于下发的文件进行爬取</a></h3><h2 id="九-进阶的实战爬虫"><a href="#九-进阶的实战爬虫" class="headerlink" title="九.进阶的实战爬虫"></a>九.进阶的实战爬虫</h2><h3 id="爬虫爬取m3u8视频文件"><a href="#爬虫爬取m3u8视频文件" class="headerlink" title="爬虫爬取m3u8视频文件"></a><a href="https://www.cnblogs.com/pythonywy/p/11696827.html" target="_blank" rel="noopener">爬虫爬取m3u8视频文件</a></h3><h3 id="爬虫模拟有道字典进行翻译-还发现了一条好玩的js"><a href="#爬虫模拟有道字典进行翻译-还发现了一条好玩的js" class="headerlink" title="爬虫模拟有道字典进行翻译,还发现了一条好玩的js"></a><a href="https://www.cnblogs.com/pythonywy/p/11354352.html" target="_blank" rel="noopener">爬虫模拟有道字典进行翻译,还发现了一条好玩的js</a></h3><h3 id="爬取斗图网图片-使用xpath格式来匹配内容-对请求伪装成浏览器-Referer-防跨域请求"><a href="#爬取斗图网图片-使用xpath格式来匹配内容-对请求伪装成浏览器-Referer-防跨域请求" class="headerlink" title="爬取斗图网图片,使用xpath格式来匹配内容,对请求伪装成浏览器, Referer 防跨域请求"></a><a href="https://www.cnblogs.com/pythonywy/p/11066842.html" target="_blank" rel="noopener">爬取斗图网图片,使用xpath格式来匹配内容,对请求伪装成浏览器, Referer 防跨域请求</a></h3><h3 id="爬虫多线程高效高速爬取图片"><a href="#爬虫多线程高效高速爬取图片" class="headerlink" title="爬虫多线程高效高速爬取图片"></a><a href="https://www.cnblogs.com/pythonywy/p/11072974.html" target="_blank" rel="noopener">爬虫多线程高效高速爬取图片</a></h3><h3 id="博客园随笔内容进行爬取至本地并转md格式"><a href="#博客园随笔内容进行爬取至本地并转md格式" class="headerlink" title="博客园随笔内容进行爬取至本地并转md格式"></a><a href="https://www.cnblogs.com/pythonywy/p/11139508.html" target="_blank" rel="noopener">博客园随笔内容进行爬取至本地并转md格式</a></h3><h3 id="爬取千千音乐动态传输内容"><a href="#爬取千千音乐动态传输内容" class="headerlink" title="爬取千千音乐动态传输内容"></a><a href="https://www.cnblogs.com/pythonywy/p/11156301.html" target="_blank" rel="noopener">爬取千千音乐动态传输内容</a></h3><h3 id="写了个爬虫代理ip的脚本给大家使用"><a href="#写了个爬虫代理ip的脚本给大家使用" class="headerlink" title="写了个爬虫代理ip的脚本给大家使用"></a><a href="https://www.cnblogs.com/pythonywy/p/11278893.html" target="_blank" rel="noopener">写了个爬虫代理ip的脚本给大家使用</a></h3><h3 id="对于房天下租房信息进行爬取"><a href="#对于房天下租房信息进行爬取" class="headerlink" title="对于房天下租房信息进行爬取"></a><a href="https://www.cnblogs.com/pythonywy/p/11259941.html" target="_blank" rel="noopener">对于房天下租房信息进行爬取</a></h3><h3 id="模拟百度进行图片搜索-有问题可以留言"><a href="#模拟百度进行图片搜索-有问题可以留言" class="headerlink" title="模拟百度进行图片搜索,有问题可以留言"></a><a href="https://www.cnblogs.com/pythonywy/p/11312010.html" target="_blank" rel="noopener">模拟百度进行图片搜索,有问题可以留言</a></h3><h3 id="爬虫极滑块验证思路"><a href="#爬虫极滑块验证思路" class="headerlink" title="爬虫极滑块验证思路"></a><a href="https://www.cnblogs.com/pythonywy/p/11773570.html" target="_blank" rel="noopener">爬虫极滑块验证思路</a></h3><h3 id="python爬虫破解知乎登入加密信息-不使用Selenium模块"><a href="#python爬虫破解知乎登入加密信息-不使用Selenium模块" class="headerlink" title="python爬虫破解知乎登入加密信息(不使用Selenium模块)"></a><a href="https://www.cnblogs.com/pythonywy/p/11714352.html" target="_blank" rel="noopener">python爬虫破解知乎登入加密信息(不使用Selenium模块)</a></h3><h3 id="python爬虫爬小说网站涉及到-js加密-CSS加密"><a href="#python爬虫爬小说网站涉及到-js加密-CSS加密" class="headerlink" title="python爬虫爬小说网站涉及到(js加密,CSS加密)"></a><a href="https://www.cnblogs.com/pythonywy/p/11720943.html" target="_blank" rel="noopener">python爬虫爬小说网站涉及到(js加密,CSS加密)</a></h3><h3 id="红薯小说爬取-加密请见谅"><a href="#红薯小说爬取-加密请见谅" class="headerlink" title="红薯小说爬取(加密请见谅)"></a><a href="https://www.cnblogs.com/pythonywy/p/11724029.html" target="_blank" rel="noopener">红薯小说爬取</a>(加密请见谅)</h3><h3 id="极滑块验证完美攻克-加密请见谅"><a href="#极滑块验证完美攻克-加密请见谅" class="headerlink" title="极滑块验证完美攻克 (加密请见谅)"></a><a href="https://www.cnblogs.com/pythonywy/p/11773424.html" target="_blank" rel="noopener">极滑块验证完美攻克</a> (加密请见谅)</h3><h2 id="十-电商相关"><a href="#十-电商相关" class="headerlink" title="十.电商相关"></a>十.电商相关</h2><h3 id="python获取淘宝登入cookies"><a href="#python获取淘宝登入cookies" class="headerlink" title="python获取淘宝登入cookies"></a><a href="https://www.cnblogs.com/pythonywy/p/12074789.html" target="_blank" rel="noopener">python获取淘宝登入cookies</a></h3><h3 id="pyppeteer硬钢掉淘宝登入的滑块验证"><a href="#pyppeteer硬钢掉淘宝登入的滑块验证" class="headerlink" title="pyppeteer硬钢掉淘宝登入的滑块验证"></a><a href="https://www.cnblogs.com/pythonywy/p/12082117.html" target="_blank" rel="noopener">pyppeteer硬钢掉淘宝登入的滑块验证</a></h3><h3 id="python爬虫-京东商品爬取"><a href="#python爬虫-京东商品爬取" class="headerlink" title="python爬虫-京东商品爬取"></a><a href="https://www.cnblogs.com/pythonywy/p/12008430.html" target="_blank" rel="noopener">python爬虫-京东商品爬取</a></h3><h3 id="amazon爬取流程与思路"><a href="#amazon爬取流程与思路" class="headerlink" title="amazon爬取流程与思路"></a><a href="https://www.cnblogs.com/pythonywy/p/12024409.html" target="_blank" rel="noopener">amazon爬取流程与思路</a></h3><h3 id="Flipcart-爬取流程"><a href="#Flipcart-爬取流程" class="headerlink" title="Flipcart 爬取流程"></a><a href="https://www.cnblogs.com/pythonywy/p/12018977.html" target="_blank" rel="noopener">Flipcart 爬取流程</a></h3><h3 id="国外电商网站snapdeal爬取流程"><a href="#国外电商网站snapdeal爬取流程" class="headerlink" title="国外电商网站snapdeal爬取流程"></a><a href="https://www.cnblogs.com/pythonywy/p/12111169.html" target="_blank" rel="noopener">国外电商网站snapdeal爬取流程</a></h3><h2 id="十一-碰到的异常"><a href="#十一-碰到的异常" class="headerlink" title="十一.碰到的异常"></a>十一.碰到的异常</h2><h3 id="爬虫之ssh证书警告错误"><a href="#爬虫之ssh证书警告错误" class="headerlink" title="爬虫之ssh证书警告错误"></a><a href="https://www.cnblogs.com/pythonywy/p/11215055.html" target="_blank" rel="noopener">爬虫之ssh证书警告错误</a></h3><h3 id="fiddler抓包syntaxview窗口乱码-1"><a href="#fiddler抓包syntaxview窗口乱码-1" class="headerlink" title="fiddler抓包syntaxview窗口乱码"></a><a href="https://www.cnblogs.com/pythonywy/p/11704821.html" target="_blank" rel="noopener">fiddler抓包syntaxview窗口乱码</a></h3><h3 id="execjs使用时异常"><a href="#execjs使用时异常" class="headerlink" title="execjs使用时异常"></a><a href="https://www.cnblogs.com/pythonywy/p/11716296.html" target="_blank" rel="noopener">execjs使用时异常</a></h3><h2 id="十二-Request-html库"><a href="#十二-Request-html库" class="headerlink" title="十二.Request-html库"></a>十二.Request-html库</h2><h3 id="爬虫最新的库requests-html库总结"><a href="#爬虫最新的库requests-html库总结" class="headerlink" title="爬虫最新的库requests-html库总结"></a><a href="https://www.cnblogs.com/pythonywy/p/11693178.html" target="_blank" rel="noopener">爬虫最新的库requests-html库总结</a></h3><h3 id="requests-html库render的使用"><a href="#requests-html库render的使用" class="headerlink" title="requests-html库render的使用"></a><a href="https://www.cnblogs.com/pythonywy/p/11694967.html" target="_blank" rel="noopener">requests-html库render的使用</a></h3><h2 id="十三-MongoDB"><a href="#十三-MongoDB" class="headerlink" title="十三.MongoDB"></a>十三.MongoDB</h2><h3 id="mongoDB"><a href="#mongoDB" class="headerlink" title="mongoDB"></a><a href="https://www.cnblogs.com/pythonywy/p/11695217.html" target="_blank" rel="noopener">mongoDB</a></h3><h2 id="十四-定时任务"><a href="#十四-定时任务" class="headerlink" title="十四.定时任务"></a>十四.定时任务</h2><h3 id="linux中crontab任务调度"><a href="#linux中crontab任务调度" class="headerlink" title="linux中crontab任务调度"></a><a href="https://www.cnblogs.com/pythonywy/p/11771238.html" target="_blank" rel="noopener">linux中crontab任务调度</a></h3><h3 id="python-schedule模块-定时任务-基于官方文档总结"><a href="#python-schedule模块-定时任务-基于官方文档总结" class="headerlink" title="python-schedule模块(定时任务)基于官方文档总结"></a><a href="https://www.cnblogs.com/pythonywy/p/11964315.html" target="_blank" rel="noopener">python-schedule模块(定时任务)基于官方文档总结</a></h3>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://sir0.net/%E7%88%AC%E8%99%AB%E4%B9%8Bssh%E8%AF%81%E4%B9%A6%E8%AD%A6%E5%91%8A%E9%94%99%E8%AF%AF/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="sir0.net">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="吴梦梦、刘玥和SL炮叔">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/%E7%88%AC%E8%99%AB%E4%B9%8Bssh%E8%AF%81%E4%B9%A6%E8%AD%A6%E5%91%8A%E9%94%99%E8%AF%AF/" class="post-title-link" itemprop="url">爬虫之ssh证书警告错误</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-03-07 23:00:57" itemprop="dateCreated datePublished" datetime="2020-03-07T23:00:57+08:00">2020-03-07</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-03-06 11:39:12" itemprop="dateModified" datetime="2020-03-06T11:39:12+08:00">2020-03-06</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="爬虫之ssh证书警告错误"><a href="#爬虫之ssh证书警告错误" class="headerlink" title="爬虫之ssh证书警告错误"></a>爬虫之ssh证书警告错误</h1><h2 id="1-错误信息"><a href="#1-错误信息" class="headerlink" title="1.错误信息"></a>1.错误信息</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">错误信息:equests.exceptions.SSLError: (<span class="string">"bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')],)"</span>,)</span><br></pre></td></tr></table></figure>
<h2 id="2-分析"><a href="#2-分析" class="headerlink" title="2.分析"></a>2.分析</h2><p>ssh证书是美国网景公司发放的一个安全认证证书，有了这个证书即可证明网站是安全的，但是认证是需要收费的，<br>所以一些网站就会自己仿造证书，这个时候浏览器就会给予警告，而我们爬虫就爬不到想要的信息</p>
<h2 id="3-解决办法"><a href="#3-解决办法" class="headerlink" title="3.解决办法"></a>3.解决办法</h2><ul>
<li>方法一:<br /><br>加上一个参数：verify=证书路径，或verify=False<br>如:<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> request</span><br><span class="line">url = <span class="string">'xxxxx'</span></span><br><span class="line">req = requests.get(url,verify=<span class="literal">False</span>)</span><br><span class="line">print(req.text)</span><br></pre></td></tr></table></figure></li>
<li>方法二:<br><code>ssl._create_default_https_context</code>=``ssl._create_unverified_context<code>#注意用了这个就不能用requests了，得用urllib2.Request</code><br>python2中</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">  # 方法二（推荐）：</span><br><span class="line">  import ssl</span><br><span class="line">import urllib2</span><br><span class="line">  </span><br><span class="line">  ssl._create_default_https_context &#x3D;ssl._create_unverified_context</span><br><span class="line">  req &#x3D;urllib2.Request(&#39;xxxx&#39;)</span><br><span class="line">  data &#x3D;urllib2.urlopen(req).read()</span><br><span class="line">  print(data)</span><br></pre></td></tr></table></figure>
<p>python3中</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> ssl</span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line">ssl._create_default_https_context =ssl._create_unverified_context</span><br><span class="line">data =urllib.request.urlopen(<span class="string">'xxxx'</span>).read()</span><br><span class="line">print(data)</span><br></pre></td></tr></table></figure>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://sir0.net/%E7%88%AC%E8%99%AB%E6%9C%80%E6%96%B0%E7%9A%84%E5%BA%93requests-html%E5%BA%93%E6%80%BB%E7%BB%93/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="sir0.net">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="吴梦梦、刘玥和SL炮叔">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/%E7%88%AC%E8%99%AB%E6%9C%80%E6%96%B0%E7%9A%84%E5%BA%93requests-html%E5%BA%93%E6%80%BB%E7%BB%93/" class="post-title-link" itemprop="url">爬虫最新的库requests-html库总结</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-03-07 23:00:57" itemprop="dateCreated datePublished" datetime="2020-03-07T23:00:57+08:00">2020-03-07</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-03-06 11:40:12" itemprop="dateModified" datetime="2020-03-06T11:40:12+08:00">2020-03-06</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p><code>requests-html是比较新的爬虫库,作者和requests是同一个作者</code></p>
<h2 id="一-安装依赖"><a href="#一-安装依赖" class="headerlink" title="一.安装依赖"></a>一.安装依赖</h2><p><code>pip install requests-html</code><br>我们可以在安装的时候看到他安装了lxml,reuqests,bs4……我们常用的解析和爬取的库都分装在他里面</p>
<h2 id="二-发起请求"><a href="#二-发起请求" class="headerlink" title="二. 发起请求"></a>二. 发起请求</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> requests_html <span class="keyword">import</span> HTMLSession</span><br><span class="line">session = HTMLSession()</span><br><span class="line"></span><br><span class="line"><span class="comment">#用法和requests.session实例化的对象用法一模一样,也会自动保存返回信息</span></span><br><span class="line"><span class="comment">#相比reuqests,他多了对于response.html这个属性</span></span><br></pre></td></tr></table></figure>
<p><code>注意点</code>:发默认发送的的是<code>无头浏览器</code>,且他如果用render<code>调用浏览器内核</code></p>
<h3 id="1-解决无头浏览器-针对反爬-如果没有做反爬无所谓"><a href="#1-解决无头浏览器-针对反爬-如果没有做反爬无所谓" class="headerlink" title="1.解决无头浏览器(针对反爬,如果没有做反爬无所谓)"></a>1.解决无头浏览器(针对反爬,如果没有做反爬无所谓)</h3><p><code>修改源码</code></p>
<ul>
<li>ctrl左键进入<code>HTMLSession</code></li>
<li>我们可以看到他是继承<code>BaseSession</code></li>
<li>ctrl左键进入<code>BaseSession</code><br><code>原来的源码</code><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BaseSession</span><span class="params">(requests.Session)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, mock_browser : bool = True, verify : bool = True,</span></span></span><br><span class="line"><span class="function"><span class="params">                 browser_args : list = [<span class="string">'--no-sandbox'</span>])</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        <span class="keyword">if</span> mock_browser:</span><br><span class="line">        self.headers[<span class="string">'User-Agent'</span>] = user_agent()</span><br><span class="line"></span><br><span class="line">        self.hooks[<span class="string">'response'</span>].append(self.response_hook)</span><br><span class="line">        self.verify = verify</span><br><span class="line"></span><br><span class="line">        self.__browser_args = browser_args</span><br><span class="line">        self.__headless = headless</span><br><span class="line"></span><br><span class="line">      <span class="comment">#中间没用的省略掉不是删掉</span></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">browser</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> hasattr(self, <span class="string">"_browser"</span>):</span><br><span class="line">            self._browser = <span class="keyword">await</span> pyppeteer.launch(ignoreHTTPSErrors=<span class="keyword">not</span>(self.verify), headless=<span class="literal">True</span>, args=self.__browser_args)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> self._browser</span><br></pre></td></tr></table></figure>
<code>修改后的源码</code><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BaseSession</span><span class="params">(requests.Session)</span>:</span></span><br><span class="line">    <span class="string">""" A consumable session, for cookie persistence and connection pooling,</span></span><br><span class="line"><span class="string">    amongst other things.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, mock_browser : bool = True, verify : bool = True,</span></span></span><br><span class="line"><span class="function"><span class="params">                 browser_args : list = [<span class="string">'--no-sandbox'</span>],headless=False)</span>:</span>       <span class="comment">#如果你设置成True他就是无头,且你再运行render时候不会弹出浏览器</span></span><br><span class="line">        super().__init__()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Mock a web browser's user agent.</span></span><br><span class="line">        <span class="keyword">if</span> mock_browser:</span><br><span class="line">            self.headers[<span class="string">'User-Agent'</span>] = user_agent()</span><br><span class="line"></span><br><span class="line">        self.hooks[<span class="string">'response'</span>].append(self.response_hook)</span><br><span class="line">        self.verify = verify</span><br><span class="line"></span><br><span class="line">        self.__browser_args = browser_args</span><br><span class="line">        self.__headless = headless</span><br><span class="line">          <span class="comment">#中间没用的省略掉不是删掉</span></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">browser</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> hasattr(self, <span class="string">"_browser"</span>):</span><br><span class="line">            self._browser = <span class="keyword">await</span> pyppeteer.launch(ignoreHTTPSErrors=<span class="keyword">not</span>(self.verify), headless=self.__headless, args=self.__browser_args)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> self._browser</span><br></pre></td></tr></table></figure>
<code>其实我就做了个处理方便传一个headless进去</code></li>
</ul>
<p>对于<code>session</code>重新设置</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> requests_html <span class="keyword">import</span> HTMLSession</span><br><span class="line">session = HTMLSession(</span><br><span class="line">browser_args=[<span class="string">'--no-sand'</span>,</span><br><span class="line">              <span class="string">'--user-agent='</span>xxxxx<span class="string">'</span></span><br><span class="line"><span class="string">             ]</span></span><br><span class="line"><span class="string">)</span></span><br><span class="line"><span class="string">#这样你就可以直接定义他是什么浏览器发送请求啦</span></span><br></pre></td></tr></table></figure>
<h3 id="2-解决浏览器内核-针对反爬-如果没有做反爬无所谓"><a href="#2-解决浏览器内核-针对反爬-如果没有做反爬无所谓" class="headerlink" title="2.解决浏览器内核(针对反爬,如果没有做反爬无所谓)"></a>2.解决浏览器内核(针对反爬,如果没有做反爬无所谓)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#利用模块进行js注入</span></span><br><span class="line"><span class="keyword">from</span> requests_html  <span class="keyword">import</span> HTMLSession</span><br><span class="line"></span><br><span class="line">session  =HTMLSession(.....)</span><br><span class="line">response = session.get(<span class="string">'https://www.baidu.com'</span>)</span><br><span class="line">script=<span class="string">'''</span></span><br><span class="line"><span class="string">()=&gt;&#123;</span></span><br><span class="line"><span class="string">Object.defineProperties(navigator,&#123;</span></span><br><span class="line"><span class="string">        webdriver:&#123;</span></span><br><span class="line"><span class="string">        get: () =&gt; undefined</span></span><br><span class="line"><span class="string">        &#125;</span></span><br><span class="line"><span class="string">    &#125;)&#125;'''</span></span><br><span class="line">print(response.html.render(script=script))</span><br></pre></td></tr></table></figure>
<h2 id="三-response-html相关属性"><a href="#三-response-html相关属性" class="headerlink" title="三.response.html相关属性"></a>三.response.html相关属性</h2><p>这里的response对象是</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from requests_html  import HTMLSession</span><br><span class="line">session  &#x3D;HTMLSession()</span><br><span class="line">response &#x3D; session.get(&#39;https:&#x2F;&#x2F;www.baidu.com&#39;)</span><br><span class="line">#为了大家好理解就这个response</span><br></pre></td></tr></table></figure>
<h3 id="1-absolute-links"><a href="#1-absolute-links" class="headerlink" title="1.absolute_links"></a>1.absolute_links</h3><p>所有的路径都会转成<code>绝对路径</code>返回</p>
<h3 id="2-links"><a href="#2-links" class="headerlink" title="2.links"></a>2.links</h3><p><code>返还路径原样</code></p>
<h3 id="3-base-url"><a href="#3-base-url" class="headerlink" title="3.base_url"></a>3.base_url</h3><p>.base标签里的路径,如果没有base标签,就是当前url</p>
<h3 id="4-html"><a href="#4-html" class="headerlink" title="4.html"></a>4.html</h3><p>返回字符串字符串内包含有标签</p>
<h3 id="5-text"><a href="#5-text" class="headerlink" title="5.text"></a>5.text</h3><p>返回字符串字符串内不包含有标签<code>爬取什么小说新闻之类的超级好用!</code></p>
<h3 id="6-encoding"><a href="#6-encoding" class="headerlink" title="6.encoding"></a>6.encoding</h3><p>解码格式,注意这里是response.html的encoding,你如果只只设置了response.encoding对这个encoding毫无影响</p>
<h3 id="7-raw-html"><a href="#7-raw-html" class="headerlink" title="7.raw_html"></a>7.raw_html</h3><p><code>相当于r.content</code>返回二进制</p>
<h3 id="8-pq"><a href="#8-pq" class="headerlink" title="8.pq"></a>8.pq</h3><p>返回PyQuery对象,个人不怎么用这个库所有不写结论</p>
<h2 id="四-response-html相关方法"><a href="#四-response-html相关方法" class="headerlink" title="四.response.html相关方法"></a>四.response.html相关方法</h2><p>下面response对象我就简写成 r了</p>
<h3 id="1-find"><a href="#1-find" class="headerlink" title="1.find"></a>1.find</h3><p>用css选择器找对象<br><code>获取全部</code><br><code>语法</code>:r.html.find(‘css选择器’)<br><code>返回值</code>:[element对象1，。。。。。] <code>是个列表</code><br><code>只获取第一个</code><br>语法<code>:r.html.find(&#39;css选择器&#39;,first = True)</code>返回值`:element对象</p>
<h3 id="2-xpath"><a href="#2-xpath" class="headerlink" title="2.xpath"></a>2.xpath</h3><p>用xpath选择器找对象<br><code>获取全部</code><br><code>语法</code>:r.html.xpath(‘xpath选择器’)<br><code>返回值</code>:[Element对象1，。。。。。] <code>是列表</code><br><code>只获取第一个</code><br>语法<code>:r.html.xpath(&#39;xpath选择器&#39;,first = True)</code>返回值`:Element对象</p>
<h3 id="3-search-只获取第一个"><a href="#3-search-只获取第一个" class="headerlink" title="3.search(只获取第一个)"></a>3.search(只获取第一个)</h3><p>类似用正则匹配,就是把正则里面的<code>(.*?)</code>变成<code>{}</code><br><code>语法</code>:r.html.search(‘模板’)<br>模板一:(‘xx{}xxx{}’)<br>获取:<code>获取第一个</code>:r.html.search(‘模板’)[0]<code>其他以此类推</code><br>模板二:（‘xxx{name}yyy{pwd}’）<br>获取:<code>获取第一个</code>:r.html.search(‘模板’)[‘name’]<code>其他以此类推</code></p>
<h3 id="4-search-all-获取全部"><a href="#4-search-all-获取全部" class="headerlink" title="4.search_all(获取全部)"></a>4.search_all(获取全部)</h3><p>用法和search一样<br>返回值: 【result对象，result对象，】</p>
<h3 id="5-render-这个我后续单独写一个总结内容有点多"><a href="#5-render-这个我后续单独写一个总结内容有点多" class="headerlink" title="5.render(这个我后续单独写一个总结内容有点多)"></a>5.render(这个我后续单独写一个总结内容有点多)</h3><p>他其实就是封装了<code>pyppeteer</code>你如果不了解<code>pyppeteer</code>,那可以想想<code>Selenium</code>就是模拟浏览器访问</p>
<h2 id="五-Element对象方法及属性"><a href="#五-Element对象方法及属性" class="headerlink" title="五.Element对象方法及属性"></a>五.Element对象方法及属性</h2><ul>
<li>absolute_links:绝对url</li>
<li>links:相对url</li>
<li>text:只显示文本</li>
<li>html:标签也会显示</li>
<li>attrs:属性</li>
<li>find(‘css选择器’)</li>
<li>xpath(‘xapth路径’)</li>
<li>.search(‘模板’)</li>
<li>.search_all(‘模板’)</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://sir0.net/%E7%88%AC%E5%8F%96%E5%8D%9A%E5%AE%A2%E5%9B%AD%E7%9A%84%E6%89%80%E6%9C%89%E9%9A%8F%E7%AC%94%E7%9A%84url%E4%BB%A5%E5%8F%8A%E8%AE%A1%E6%95%B0,%E8%BF%98%E6%9C%89%E5%AF%B9%E5%BA%94%E6%A0%87%E9%A2%98/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="sir0.net">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="吴梦梦、刘玥和SL炮叔">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/%E7%88%AC%E5%8F%96%E5%8D%9A%E5%AE%A2%E5%9B%AD%E7%9A%84%E6%89%80%E6%9C%89%E9%9A%8F%E7%AC%94%E7%9A%84url%E4%BB%A5%E5%8F%8A%E8%AE%A1%E6%95%B0,%E8%BF%98%E6%9C%89%E5%AF%B9%E5%BA%94%E6%A0%87%E9%A2%98/" class="post-title-link" itemprop="url">爬取博客园的所有随笔的url以及计数,还有对应标题</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-03-07 23:00:57" itemprop="dateCreated datePublished" datetime="2020-03-07T23:00:57+08:00">2020-03-07</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-03-06 11:38:53" itemprop="dateModified" datetime="2020-03-06T11:38:53+08:00">2020-03-06</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="1-爬取博客园的所有随笔的url以及计数-还有对应标题"><a href="#1-爬取博客园的所有随笔的url以及计数-还有对应标题" class="headerlink" title="1.爬取博客园的所有随笔的url以及计数,还有对应标题"></a>1.爬取博客园的所有随笔的url以及计数,还有对应标题</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> lxml.html <span class="keyword">import</span> etree</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="comment">#对于链接和标题的一个整合</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">func_1_deco</span><span class="params">(func_1)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">wrapper</span><span class="params">(*args,**kwargs)</span>:</span></span><br><span class="line">        dic = dict()</span><br><span class="line">        lis = func_1(*args,**kwargs)</span><br><span class="line">        count = lis[<span class="number">0</span>]</span><br><span class="line">        url_lis = lis[<span class="number">1</span>]</span><br><span class="line">        dic[<span class="string">'count'</span>] = count</span><br><span class="line">        name_xpath = <span class="string">'//*[@id="cb_post_title_url"]/text()'</span></span><br><span class="line">        <span class="keyword">for</span> url <span class="keyword">in</span> url_lis:</span><br><span class="line">            response = requests.get(url)</span><br><span class="line">            response = response.text</span><br><span class="line">            response_html = etree.HTML(response)</span><br><span class="line">            name = response_html.xpath(name_xpath)[<span class="number">0</span>]</span><br><span class="line">            print(name)</span><br><span class="line">            dic[name] = url</span><br><span class="line">        <span class="keyword">return</span> dic</span><br><span class="line">    <span class="keyword">return</span> wrapper</span><br><span class="line"></span><br><span class="line"><span class="meta">@func_1_deco</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">func</span><span class="params">(url)</span>:</span></span><br><span class="line">    lis = []</span><br><span class="line">    count = <span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        count_1 = len(lis)</span><br><span class="line">        response = requests.get(<span class="string">f'<span class="subst">&#123;url&#125;</span>default.html?page=<span class="subst">&#123;count&#125;</span>'</span>)</span><br><span class="line">        response = response.text</span><br><span class="line">        data_1 = re.findall(<span class="string">' href="(.*?)"'</span>, response, re.S)</span><br><span class="line">        <span class="keyword">for</span> a <span class="keyword">in</span> data_1:  <span class="comment"># type:str</span></span><br><span class="line">            <span class="keyword">if</span> a.startswith(<span class="string">'http'</span>):</span><br><span class="line">                <span class="keyword">if</span> a.endswith(<span class="string">'html'</span>):</span><br><span class="line">                    <span class="keyword">if</span> <span class="string">'archive'</span> <span class="keyword">not</span> <span class="keyword">in</span> a:</span><br><span class="line">                        lis.append(a)</span><br><span class="line">        count +=<span class="number">1</span></span><br><span class="line">        lis = set(lis)</span><br><span class="line">        lis = list(lis)</span><br><span class="line">        count_2 = len(lis)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> count_1 == count_2:</span><br><span class="line">            <span class="keyword">return</span> count_2,lis  <span class="comment">#博客的数据量,博客里面随笔的url</span></span><br><span class="line"></span><br><span class="line">        </span><br><span class="line">dic = func(<span class="string">'你的博客的首页地址'</span>) <span class="comment">#注意结尾要有/,字典格式是有一栏'count'计数,其他均为标题+对应的url</span></span><br></pre></td></tr></table></figure>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://sir0.net/%E7%88%AC%E5%8F%96%E6%96%97%E5%9B%BE%E7%BD%91%E5%9B%BE%E7%89%87,%E4%BD%BF%E7%94%A8xpath%E6%A0%BC%E5%BC%8F%E6%9D%A5%E5%8C%B9%E9%85%8D%E5%86%85%E5%AE%B9,%E5%AF%B9%E8%AF%B7%E6%B1%82%E4%BC%AA%E8%A3%85%E6%88%90%E6%B5%8F%E8%A7%88%E5%99%A8,%20Referer%20%E9%98%B2%E8%B7%A8%E5%9F%9F%E8%AF%B7%E6%B1%82/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="sir0.net">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="吴梦梦、刘玥和SL炮叔">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/%E7%88%AC%E5%8F%96%E6%96%97%E5%9B%BE%E7%BD%91%E5%9B%BE%E7%89%87,%E4%BD%BF%E7%94%A8xpath%E6%A0%BC%E5%BC%8F%E6%9D%A5%E5%8C%B9%E9%85%8D%E5%86%85%E5%AE%B9,%E5%AF%B9%E8%AF%B7%E6%B1%82%E4%BC%AA%E8%A3%85%E6%88%90%E6%B5%8F%E8%A7%88%E5%99%A8,%20Referer%20%E9%98%B2%E8%B7%A8%E5%9F%9F%E8%AF%B7%E6%B1%82/" class="post-title-link" itemprop="url">爬取斗图网图片,使用xpath格式来匹配内容,对请求伪装成浏览器, Referer 防跨域请求</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-03-07 23:00:57" itemprop="dateCreated datePublished" datetime="2020-03-07T23:00:57+08:00">2020-03-07</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-03-06 11:40:07" itemprop="dateModified" datetime="2020-03-06T11:40:07+08:00">2020-03-06</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="6-21自我总结"><a href="#6-21自我总结" class="headerlink" title="6.21自我总结"></a>6.21自我总结</h1><h2 id="一-爬取斗图网"><a href="#一-爬取斗图网" class="headerlink" title="一.爬取斗图网"></a>一.爬取斗图网</h2><h3 id="1-摘要"><a href="#1-摘要" class="headerlink" title="1.摘要"></a>1.摘要</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">使用xpath匹配规则查找对应信息文件</span><br><span class="line">将请求伪装成浏览器</span><br><span class="line">Referer 防跨域请求</span><br></pre></td></tr></table></figure>
<h3 id="2-爬取代码"><a href="#2-爬取代码" class="headerlink" title="2.爬取代码"></a>2.爬取代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#导入模块</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="comment">#爬取网址</span></span><br><span class="line">url = <span class="string">'http://www.doutula.com/'</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#伪装成成浏览器请求</span></span><br><span class="line"><span class="comment">#找到request200,200代表请求成功的里面的内容,按F12里面找</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">Referer: http://www.doutula.com/  Referer为防跨域请求,我看了下图片都是这个所有也可以不加上去,这个简单来说就是你只能通过这个网址来找到图片,如果他和url不同我们也把他加入再hearders里面,和下面保存一起</span></span><br><span class="line"><span class="string">User-Agent: Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.131 Safari/537.36</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#编程字典,为了把我们请求伪装成浏览器</span></span><br><span class="line">hearders = &#123;<span class="string">'User-Agent'</span>:<span class="string">'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.131 Safari/537.36'</span>,&#125;</span><br><span class="line"></span><br><span class="line">response = requests.get(url,headers=hearders) <span class="comment">#hearders是请求头,body是请求主体</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#成功拿到响应</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#查找的内容</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">data-original="http://ww4.sinaimg.cn/bmiddle/9150e4e5gy1g48gluqdp6j203c03ct92.jpg" </span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#我们用xpath进行查找</span></span><br><span class="line"><span class="comment">#我们去页面找,他对应的xpath</span></span><br><span class="line">img_xpath = <span class="string">'.//img/@data-original'</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#解析</span></span><br><span class="line"><span class="keyword">from</span> lxml.html <span class="keyword">import</span> etree</span><br><span class="line"><span class="comment">#把爬取的内容变成html格式</span></span><br><span class="line">html = etree.HTML(response.text) <span class="comment">#我们请求下来的内容要以text格式</span></span><br><span class="line"><span class="comment">#把xpath的匹配规则丢进去</span></span><br><span class="line">img_url = html.xpath(img_xpath)</span><br><span class="line"><span class="comment">#print(img_url)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#保存文件</span></span><br><span class="line"><span class="comment">#创建个文件夹</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="comment">#创建当前文件夹位置一个img文件夹</span></span><br><span class="line">img_file_path = os.path.join(os.path.dirname(__file__),<span class="string">'img'</span>)  <span class="comment">#获得文件夹名</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(img_file_path): <span class="comment">#没有文件夹名创建文件夹</span></span><br><span class="line">    os.mkdir(img_file_path)</span><br><span class="line"></span><br><span class="line"><span class="comment">#把图片保存进该文件夹</span></span><br><span class="line">count = <span class="number">1</span> <span class="comment">#用于计数</span></span><br><span class="line"><span class="keyword">for</span> img <span class="keyword">in</span> img_url:</span><br><span class="line"></span><br><span class="line">    img_path = os.path.join(img_file_path,<span class="string">f'第<span class="subst">&#123;count&#125;</span>张.jpg'</span>)    <span class="comment">#创建图片名称</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> open(img_path,<span class="string">'wb'</span>) <span class="keyword">as</span> fw:</span><br><span class="line"></span><br><span class="line">        <span class="comment">#获取图片的二进制形式</span></span><br><span class="line">        img_response = requests.get(img)</span><br><span class="line">        img_response = img_response.content</span><br><span class="line"></span><br><span class="line">        <span class="comment">#写入文件</span></span><br><span class="line">        fw.write(img_response)</span><br><span class="line">        count +=<span class="number">1</span></span><br></pre></td></tr></table></figure>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://sir0.net/%E7%88%AC%E5%8F%96%E8%B1%86%E7%93%A3%E7%94%B5%E5%BD%B1%E6%8E%92%E5%90%8D%E7%9A%84%E4%BB%A3%E7%A0%81%E4%BB%A5%E5%8F%8A%E6%80%9D%E8%B7%AF/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="sir0.net">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="吴梦梦、刘玥和SL炮叔">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/%E7%88%AC%E5%8F%96%E8%B1%86%E7%93%A3%E7%94%B5%E5%BD%B1%E6%8E%92%E5%90%8D%E7%9A%84%E4%BB%A3%E7%A0%81%E4%BB%A5%E5%8F%8A%E6%80%9D%E8%B7%AF/" class="post-title-link" itemprop="url">爬取豆瓣电影排名的代码以及思路</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-03-07 23:00:57" itemprop="dateCreated datePublished" datetime="2020-03-07T23:00:57+08:00">2020-03-07</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-03-06 11:39:53" itemprop="dateModified" datetime="2020-03-06T11:39:53+08:00">2020-03-06</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p><code>博问上到有人问的,后自己帮他代码修正了一下,其实蛮简单的一个爬虫</code></p>
<h2 id="代码以及思路"><a href="#代码以及思路" class="headerlink" title="代码以及思路"></a>代码以及思路</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> requests_html <span class="keyword">import</span> HTMLSession</span><br><span class="line"></span><br><span class="line">session = HTMLSession()  <span class="comment">#定义一个session对象,和reuqests模块中的session是一样的</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_movie</span><span class="params">()</span>:</span></span><br><span class="line">    </span><br><span class="line">    movie_list=[]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, <span class="number">10</span>):  <span class="comment">#前250名</span></span><br><span class="line">        </span><br><span class="line">        print(<span class="string">f'<span class="subst">&#123;i+<span class="number">1</span>&#125;</span>页'</span>)</span><br><span class="line">        link = <span class="string">f'https://movie.douban.com/top250?start=<span class="subst">&#123;i*<span class="number">25</span>&#125;</span>'</span> <span class="comment">#这里呢稍微点几页你就知道规律了</span></span><br><span class="line">        print(link)</span><br><span class="line">        response = session.get(link)   <span class="comment">#这里很多人都有误区总是喜欢加User-Agen,个人感觉他反爬的时候用到这个再加,人家都没设这方面的反爬加了也没啥意义</span></span><br><span class="line">        </span><br><span class="line">        div_list = response.html.find(<span class="string">'.info'</span>)  <span class="comment">#你也可以获取info类下的电影信息</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> each <span class="keyword">in</span> div_list:</span><br><span class="line">            movie = each.text  <span class="comment">#获取里面所有字符串</span></span><br><span class="line">            movie_list.append(movie)  <span class="comment">#加列表你可以存数据库,这随意</span></span><br><span class="line">    <span class="keyword">return</span> movie_list</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    print(get_movie())</span><br></pre></td></tr></table></figure>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://sir0.net/%E7%88%AC%E5%8F%96%E5%8D%83%E5%8D%83%E9%9F%B3%E4%B9%90/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="sir0.net">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="吴梦梦、刘玥和SL炮叔">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/%E7%88%AC%E5%8F%96%E5%8D%83%E5%8D%83%E9%9F%B3%E4%B9%90/" class="post-title-link" itemprop="url">爬取千千音乐</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-03-07 23:00:57" itemprop="dateCreated datePublished" datetime="2020-03-07T23:00:57+08:00">2020-03-07</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-03-06 11:39:27" itemprop="dateModified" datetime="2020-03-06T11:39:27+08:00">2020-03-06</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="爬取千千音乐动态传输内容"><a href="#爬取千千音乐动态传输内容" class="headerlink" title="爬取千千音乐动态传输内容"></a>爬取千千音乐动态传输内容</h1><h2 id="1-首先千千音乐的robots协议"><a href="#1-首先千千音乐的robots协议" class="headerlink" title="1.首先千千音乐的robots协议"></a>1.首先千千音乐的robots协议</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">User-agent: Baiduspider</span><br><span class="line">Allow: &#x2F;</span><br><span class="line"></span><br><span class="line">User-agent: Baiduspider-image</span><br><span class="line">Allow: &#x2F;</span><br><span class="line"></span><br><span class="line">User-agent: YoudaoBot</span><br><span class="line">Allow: &#x2F;</span><br><span class="line"></span><br><span class="line">User-agent: Sogou web spider</span><br><span class="line">Allow: &#x2F;</span><br><span class="line"></span><br><span class="line">User-agent: Sogou inst spider</span><br><span class="line">Allow: &#x2F;</span><br><span class="line"></span><br><span class="line">User-agent: Sogou spider2</span><br><span class="line">Allow: &#x2F;</span><br><span class="line"></span><br><span class="line">User-agent: Sogou blog</span><br><span class="line">Allow: &#x2F;</span><br><span class="line"></span><br><span class="line">User-agent: Sogou News Spider</span><br><span class="line">Allow: &#x2F;</span><br><span class="line"></span><br><span class="line">User-agent: Sogou Orion spider</span><br><span class="line">Allow: &#x2F;</span><br><span class="line"></span><br><span class="line">User-agent: Sosospider</span><br><span class="line">Allow: &#x2F;</span><br><span class="line"></span><br><span class="line">User-agent: 360Spider</span><br><span class="line">Allow: &#x2F;</span><br><span class="line"> </span><br><span class="line">User-agent: Sogouspider</span><br><span class="line">Allow: &#x2F;</span><br><span class="line"> </span><br><span class="line">User-agent: *</span><br><span class="line">Disallow: &#x2F;</span><br></pre></td></tr></table></figure>
<h2 id="2-项目目的"><a href="#2-项目目的" class="headerlink" title="2.项目目的"></a>2.项目目的</h2><p>对于千千音乐的首页的歌单进行爬取,创建以歌单为名字的文件夹并且下载歌单内的所有歌曲保存至本地</p>
<h2 id="3-项目介绍功能介绍"><a href="#3-项目介绍功能介绍" class="headerlink" title="3.项目介绍功能介绍"></a>3.项目介绍功能介绍</h2><p>难点:千千音乐他音频是由JS生成的难点就是找到他的js链接<br>不要加<code>多进程</code>与<code>多线程</code>进去增加千千音乐的负担,只做类人爬取,对于技术的练习<br>爬取内容<code>请不要用做商业用途</code></p>
<h2 id="4-项目链接"><a href="#4-项目链接" class="headerlink" title="4.项目链接"></a>4.项目链接</h2><p><a href="https://github.com/a568972484/spider_music" target="_blank" rel="noopener">https://github.com/a568972484/spider_music</a><br>具体查看项目</p>
<h2 id="5-代码展示"><a href="#5-代码展示" class="headerlink" title="5.代码展示"></a>5.代码展示</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> lxml.html <span class="keyword">import</span> etree</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">headers = &#123;<span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.131 Safari/537.36'</span>, &#125;</span><br><span class="line"><span class="comment">#输出字典形式 歌单名字:url</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">musics_name_urls_dict</span><span class="params">()</span>:</span></span><br><span class="line"></span><br><span class="line">    response = requests.get(<span class="string">'http://music.taihe.com/'</span>,headers= headers)</span><br><span class="line">    response.encoding = <span class="string">'utf8'</span></span><br><span class="line">    response_html = etree.HTML(response.text)</span><br><span class="line">    music_xpath = <span class="string">'//*[@id="app"]/div/div[1]/section/section/div/div/div/div/div/h3/a/@href'</span></span><br><span class="line">    music_name_xpath = <span class="string">'//*[@id="app"]/div/div[1]/section/section/div/div/div/div/div/h3/a/@title'</span></span><br><span class="line">    music_urls = response_html.xpath(music_xpath)</span><br><span class="line">    music_urls_list = []</span><br><span class="line">    <span class="keyword">for</span> urls <span class="keyword">in</span> music_urls:</span><br><span class="line">        music_urls_list.append(<span class="string">f'http://music.taihe.com/<span class="subst">&#123;urls&#125;</span>'</span>)</span><br><span class="line">    music_name = response_html.xpath(music_name_xpath)</span><br><span class="line">    music_name_urls_zip = zip(music_name,music_urls_list)</span><br><span class="line">    <span class="keyword">return</span> dict(music_name_urls_zip)</span><br><span class="line"></span><br><span class="line"><span class="comment">#根据歌单新建歌单名字的文件夹位置放在D:\music\下面,并且把歌单中歌曲的名字和歌曲的url放置在一个txt文本文档中格式为歌名:url</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">music_name_urls</span><span class="params">(musics_name_url_sdict:dict)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> name,urls <span class="keyword">in</span> musics_name_url_sdict.items():</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 创建文件夹music</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">'D:\\music\\'</span>):</span><br><span class="line">            os.mkdir(<span class="string">'D:\\music\\'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># c创建歌单文件夹</span></span><br><span class="line">        <span class="comment"># 创建歌单时候歌单的名字由字符串,字母,下划线组成</span></span><br><span class="line">        name = re.sub(<span class="string">'\W'</span>,<span class="string">''</span>,name)</span><br><span class="line">        file_path = os.path.join(<span class="string">'D:\\music\\'</span>,<span class="string">f'《<span class="subst">&#123;name&#125;</span>》'</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(file_path):</span><br><span class="line">            os.mkdir(file_path)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#获取歌单中的歌曲名和url</span></span><br><span class="line">        headers = &#123;<span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.131 Safari/537.36'</span>, &#125;</span><br><span class="line">        response = requests.get(urls, headers=headers)</span><br><span class="line">        response.encoding = <span class="string">'utf8'</span></span><br><span class="line">        response_html = etree.HTML(response.text)</span><br><span class="line">        music_name_xpath = <span class="string">'// *[ @ id = "songList"]/div/ul/li/div[2]/span/a[1]/@title'</span> <span class="comment">#歌名</span></span><br><span class="line">        music_xpath = <span class="string">'// *[ @ id = "songList"]/div/ul/li/div[2]/span/a[1]/@href'</span>  <span class="comment">#歌曲链接</span></span><br><span class="line">        music_singers_xpath  = <span class="string">'//*[@id="songList"]/div/ul/li/div[3]/span/a[1]/@title'</span> <span class="comment">#歌手名称</span></span><br><span class="line">        music_urls = response_html.xpath(music_xpath)</span><br><span class="line">        music_urls_list = []</span><br><span class="line">        <span class="keyword">for</span> urls <span class="keyword">in</span> music_urls:</span><br><span class="line">            music_urls_list.append(<span class="string">f'http://music.taihe.com/<span class="subst">&#123;urls&#125;</span>'</span>)</span><br><span class="line">        music_name = response_html.xpath(music_name_xpath)</span><br><span class="line">        music_singers = response_html.xpath(music_singers_xpath)</span><br><span class="line"></span><br><span class="line">        name_url_singers_zip = zip(music_name,music_urls_list,music_singers)</span><br><span class="line">        <span class="comment">#写入txt文件</span></span><br><span class="line">        <span class="keyword">for</span> name,url,singers <span class="keyword">in</span> name_url_singers_zip:</span><br><span class="line">            <span class="keyword">with</span> open(<span class="string">f'<span class="subst">&#123;file_path&#125;</span>\\歌名和歌地址.txt'</span>,<span class="string">'a'</span>,encoding=<span class="string">'utf8'</span>) <span class="keyword">as</span> fa:</span><br><span class="line">                fa.write(<span class="string">f'<span class="subst">&#123;name&#125;</span>-<span class="subst">&#123;singers&#125;</span>&amp;amp;<span class="subst">&#123;url&#125;</span>\n'</span>)</span><br><span class="line">        print(<span class="string">f'<span class="subst">&#123;file_path&#125;</span>      歌单生成完毕'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#根据生成的歌单的txt文档我们对TXT文档进行分析,分析后的内容为歌单与其对应的内容歌名+id的一个zip文件</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_music_name_id</span><span class="params">()</span>:</span></span><br><span class="line">    catalog = os.listdir(<span class="string">'D:\\music\\'</span>)</span><br><span class="line">    print(catalog)</span><br><span class="line">    <span class="comment">#如果目录没有这个文件</span></span><br><span class="line">    lis = []   <span class="comment">#一个歌单放一个列表中</span></span><br><span class="line">    <span class="keyword">for</span> music_lis <span class="keyword">in</span> catalog:</span><br><span class="line">        music_txt_path = os.path.join(<span class="string">'D:\\music\\'</span>,music_lis,<span class="string">'歌名和歌地址.txt'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#读取文件中的歌名+歌手,以及歌曲ID,并组成字典</span></span><br><span class="line">        <span class="keyword">with</span> open(music_txt_path,<span class="string">'r'</span>,encoding=<span class="string">'utf8'</span>) <span class="keyword">as</span> fr:</span><br><span class="line"></span><br><span class="line">            dic = &#123;&#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> name_url <span class="keyword">in</span> fr:</span><br><span class="line">                name_url_list = name_url.strip().split(<span class="string">'&amp;amp;'</span>)</span><br><span class="line"></span><br><span class="line">                <span class="comment">#获取歌曲名字,和生成后歌曲的路径</span></span><br><span class="line"></span><br><span class="line">                music_name = name_url_list[<span class="number">0</span>]</span><br><span class="line">                music_file_path = os.path.join(<span class="string">'D:\\music\\'</span>,music_lis,<span class="string">f'<span class="subst">&#123;music_name&#125;</span>.mp3'</span>)</span><br><span class="line"></span><br><span class="line">                <span class="comment">#歌曲的链接</span></span><br><span class="line">                music_id = name_url_list[<span class="number">1</span>].split(<span class="string">'/'</span>)[<span class="number">-1</span>]</span><br><span class="line">                dic[music_name] = music_id</span><br><span class="line"></span><br><span class="line">            lis.append(dic)</span><br><span class="line">    <span class="keyword">return</span> zip(catalog,lis)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#歌曲进行下载</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dump_music</span><span class="params">(zip)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> music_file,music_name_id_dic <span class="keyword">in</span> zip:</span><br><span class="line">        file_path = os.path.join(<span class="string">'D:\\music\\'</span>,music_file)</span><br><span class="line">        <span class="keyword">for</span> name,id <span class="keyword">in</span> music_name_id_dic.items():</span><br><span class="line"></span><br><span class="line">            url = <span class="string">f'<span class="subst">&#123;id&#125;</span>'</span>  <span class="comment">#这里是错误滴,正确的在我guilb上,你们自己去瞧瞧哈,好用给颗星星谢谢</span></span><br><span class="line">            music_file_path = os.path.join(file_path,<span class="string">f'<span class="subst">&#123;name&#125;</span>.mp3'</span>)</span><br><span class="line"></span><br><span class="line">            data = requests.get(url,headers=headers)</span><br><span class="line">            data_text = re.sub(<span class="string">'/'</span>,<span class="string">''</span>,data.text)</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                <span class="comment">#获取歌曲URL</span></span><br><span class="line">                music_url = re.findall(<span class="string">'"file_link":(.*?),'</span>,data_text)[<span class="number">0</span>]</span><br><span class="line">                music_url = music_url.replace(<span class="string">'\\\\'</span>,<span class="string">'\\'</span>)</span><br><span class="line">                music_url = music_url.replace(<span class="string">'"'</span>,<span class="string">''</span>)</span><br><span class="line">                music_url = music_url.replace(<span class="string">'http:\\'</span>,<span class="string">'http:\\\\'</span>)</span><br><span class="line">                music_url = music_url.replace(<span class="string">'\\'</span>,<span class="string">'/'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">                <span class="comment">#下载歌曲</span></span><br><span class="line">                <span class="comment">#获取内容</span></span><br><span class="line">                response = requests.get(music_url, headers=headers)</span><br><span class="line">                response_data = response.content</span><br><span class="line"></span><br><span class="line">                <span class="comment">#下载到本地</span></span><br><span class="line">                <span class="keyword">with</span> open(music_file_path,<span class="string">'wb'</span>) <span class="keyword">as</span> fw:</span><br><span class="line">                    fw.write(response_data)</span><br><span class="line">                text_path = os.path.join(file_path, <span class="string">'下载成功的歌曲.txt'</span>)</span><br><span class="line">                <span class="keyword">with</span> open(text_path,<span class="string">'a'</span>,encoding=<span class="string">'utf8'</span>) <span class="keyword">as</span> fa:</span><br><span class="line">                    fa.write(<span class="string">f'歌曲名:<span class="subst">&#123;name&#125;</span>\n歌曲ID:<span class="subst">&#123;id&#125;</span>\n请求url:<span class="subst">&#123;music_url&#125;</span>\n'</span>)</span><br><span class="line">                print(name,<span class="string">'下载成功'</span>)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">except</span>:</span><br><span class="line">                <span class="comment">#可能会存在见状新可以到时候单独进行处理</span></span><br><span class="line">                print(name,id,<span class="string">'url匹配失败'</span>)</span><br><span class="line">                text_path = os.path.join(file_path,<span class="string">'匹配失败歌曲.txt'</span>)</span><br><span class="line">                <span class="keyword">with</span> open(text_path,<span class="string">'a'</span>,encoding=<span class="string">'utf8'</span>) <span class="keyword">as</span> fa:</span><br><span class="line">                    fa.write(<span class="string">f'歌曲名:<span class="subst">&#123;name&#125;</span>\n歌曲ID:<span class="subst">&#123;id&#125;</span>\n请求url:<span class="subst">&#123;url&#125;</span>\n'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    print(<span class="string">'开始'</span>)</span><br><span class="line">    <span class="comment">#保存文本创建文件夹</span></span><br><span class="line">    music_name_urls(musics_name_urls_dict())</span><br><span class="line"></span><br><span class="line">    <span class="comment">#读取文件夹</span></span><br><span class="line">    dump_music(get_music_name_id())</span><br><span class="line"></span><br><span class="line">    <span class="comment">#最后文件创建再D盘中</span></span><br></pre></td></tr></table></figure>
<h2 id="6-作者"><a href="#6-作者" class="headerlink" title="6.作者"></a>6.作者</h2><p>作者名称:a568972484<br>作者博客:小小咸鱼ywy<br>博客链接:<code>https://www.cnblogs.com/pythonywy</code></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

  </div>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/7/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/7/">7</a><span class="page-number current">8</span><a class="page-number" href="/page/9/">9</a><span class="space">&hellip;</span><a class="page-number" href="/page/14/">14</a><a class="extend next" rel="next" href="/page/9/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">sir0.net</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">131</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">sir0.net</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v4.2.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> v7.7.2
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  
  <script>
    (function(){
      var bp = document.createElement('script');
      var curProtocol = window.location.protocol.split(':')[0];
      bp.src = (curProtocol === 'https') ? 'https://zz.bdstatic.com/linksubmit/push.js' : 'http://push.zhanzhang.baidu.com/push.js';
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(bp, s);
    })();
  </script>















  

  

</body>
</html>
